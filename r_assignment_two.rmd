---
title: "R Assignment Two"
author: "Katherine Wolf"
date: "February 11, 2020"
output:
    pdf_document:
       includes:
         in_header: preamble-latex.tex
    html_document:
       includes:
         before_body: preamble-mathjax.tex
    latex_engine: xelatex
mainfont: Calibri
monofont: Lucida Console
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      message = FALSE)

```


```{r load required packages and read data}

library(foreign)
library(boot)
load("frmgham_recoded.wide.Rdata")

```


```{r}

# Make 2nd category (BMI 18.5-24.9, ideal weight) the referent group:
frmgham_recoded.wide$bmi_cat <- 
  relevel(as.factor(frmgham_recoded.wide$bmi_cat),"2")

```


```{r}

standardized.measures <- function(dataset, index){
  # Create resampled version of dataset using index vector:
  dataset.resampled <- dataset[index,];

  # Fit logistic regression from the resampled dataset:
  # Outcome: hyperten
  # Covariates: bmi_cat, cursmoke, age, sex, educ
  # Store results in object called logistic.frmgham
  
  logistic.frmgham <- ##### COMPLETE ON OWN 
    glm(hyperten ~ bmi_cat + cursmoke + age + sex + educ,
        data = dataset.resampled, 
        family = binomial(link = "logit"))
  
  ##### end complete on own
  
  ### To calculate the measures of association:

  # STEP 1: Create two new versions of the *original* dataset, called
  # frmgham_recoded.wide.obese and frmgham_recoded.wide.ideal
  frmgham_recoded.wide.obese <- 
    frmgham_recoded.wide.ideal <- 
    frmgham_recoded.wide

  # Set BMI to obese (category 4) in population 1 [exposed]
  # and ideal weight (category 2) in population 0 [unexposed]:
  frmgham_recoded.wide.obese$bmi_cat <- "4" # population w/ all obese
  frmgham_recoded.wide.ideal$bmi_cat <- "2" # population w/ all ideal weight

  # STEP 2: Obtain predicted individual risk of hypertension under each new dataset:
  rhat.obese <- predict(logistic.frmgham, type = "response",
                        newdata = frmgham_recoded.wide.obese)
  rhat.ideal <- predict(logistic.frmgham, type = "response",
                        newdata=frmgham_recoded.wide.ideal)

  # STEP 3: Calculate the average risk (proportion) of hypertension
  # in each hypothetical population:
  risk.obese <- mean(rhat.obese)
  risk.ideal <- mean(rhat.ideal)
  
  # Calculate risk difference and risk ratio using ideal weight as reference:
  rd <- risk.obese - risk.ideal
  rr <- risk.obese/risk.ideal

  # STEP 4: Return these estimates:
  return(c(rd, rr))
}

```




```{r}

n.frmgham <- nrow(frmgham_recoded.wide)
stdized.measures <- standardized.measures(frmgham_recoded.wide, 
                                          index=seq(1:n.frmgham))
stdized.rd <- stdized.measures[1] # Risk difference is 1st element
stdized.rr <- stdized.measures[2] # Risk ratio is 2nd element

```



```{r}

set.seed(123)
# Put the bootstrapped sample results into object called bs.standardized
bs.standardized <- boot(frmgham_recoded.wide, standardized.measures, 5000)

if(!exists("ci.rd.bca")) {
  ci.rd.bca <- boot.ci(bs.standardized, type= "bca", index=1)
}

if(!exists("ci.rr.bca")) {
  ci.rr.bca <- boot.ci(bs.standardized, type= "bca", index=2)
}

```


```{r}

rd.samples <- bs.standardized$t[,1]  # risk difference
rr.samples <- bs.standardized$t[,2]  # risk ratio

```

```{r on my own pretending}

# Calculate the standard deviation of each of the series of bootstrapped samples obtained in the above code chunk (use the log-scale for the relative measure). Calculate these centered on the original point estimate (not the sample means).

sd.rd.boot <- sd(rd.samples - stdized.rd)

sd.log.rr.boot <- sd(log(rr.samples) - log(stdized.rr))

# Use these estimates of standard deviation to calculate 95 confidence intervals for the RD and RR using a Normal approximation approach (see slide 12 from lecture notes). (Hint: make sure to do the CI calculation for the RR on the log scale and transform back to ratio scale.)

rd.ci.norm.apx <- c(stdized.rd - 1.96*sd.rd.boot, 
                    stdized.rd + 1.96*sd.rd.boot)

log.rr.ci.norm.apx <- c(log(stdized.rr) - 1.96*sd.log.rr.boot,
                        log(stdized.rr) + 1.96*sd.log.rr.boot)

rr.ci.norm.apx <- exp(log.rr.ci.norm.apx)

```

# Question One

## State the point estimate and 95% confidence interval for the estimated risk difference and risk ratio for this analysis (20 points)

The estimated standardized risk (cumulative incidence) difference, comparing the modeled cumulative incidence of hypertension over the study period in a hypothetical study population in which everyone is obese to that in a hypothetical study population in which everyone is "ideal" weight, is `r round(stdized.rd, 3)` (95% confidence interval: `r round(ci.rd.bca$bca[4], 3)`, `r round(ci.rd.bca$bca[5], 3)`). (The confidence interval is calculated around the original standardized point estimate for the risk difference using the bias-corrected and accelerated method in the `boot` R package.)

The estimated standardized risk (cumulative incidence) ratio, comparing the modeled cumulative incidence of hypertension over the study period in a hypothetical study population in which everyone is obese to that in a hypothetical study population in which everyone is "ideal" weight, is `r round(stdized.rr, 3)` (95% confidence interval: `r round(ci.rr.bca$bca[4], 3)`, `r round(ci.rr.bca$bca[5], 3)`). (The confidence interval is calculated around the original standardized point estimate for the risk ratio using the bias-corrected and accelerated method via the `boot` package.)

\pagebreak

# Question Two

## Turn in the density plots for the risk difference and risk ratio measures. Briefly describe the pattern that you see. Does the pattern seem to indicate that the sampling distribution of the RD and RR are approximately normal? (10 points)

```{r}

par(mfrow=c(3,1))
plot(density(rd.samples), main = "Bootstrapped Samples of Risk Difference")
plot(density(rr.samples), main = "Bootstrapped Samples of Risk Ratio")
plot(density(log(rr.samples)), main = "Bootstrapped Samples of Log Risk Ratio")
par(mfrow=c(1,1))

```

The density plots for the sampling distributions for the risk difference and the risk ratio drawn from bootstrapped samples of the data look normal and centered close to the point estimates from question one, as does the density plot for the sampling distribution of the natural logarithm of the risk ratio.  Thus we can likely use normal approximations to calculate 95% confidence intervals for both the risk difference and the logarithm of the risk ratio. (I don't quite understand why the original assignment had us look at a density plot for the sampling distribution of the risk ratio if we're calculating 95% confidence intervals on the scale of the predictors, which corresponds to the natural logarithm of the risk ratio.)

\pagebreak

# Question Three

```{r back-of-the-envelope, results=FALSE}

# risk difference comparisons

# true value 0.234

# bca ci 0.169, 0.292

# normal ci 0.172, 0.297

# bca middle
(0.169 + 0.292)/2

# bca size
0.292 - 0.169

# normal ci middle
(0.172 + 0.297)/2

# normal size
0.297 - 0.172

# risk ratio comparisons

# true value 1.388

# bca ci 1.273, 1.497

# normal ci 1.279, 1.506

# bca middle
(1.273 + 1.497)/2
# bca size
1.497 - 1.273

# normal ci middle
(1.279 + 1.506)/2

# normal ci size
1.506 - 1.279

```

## Showing your work, calculate the 95% confidence interval for the risk difference using a normal approximation, and report your answer. (Show the formula you used, and the specific values that went into your calculation.) What assumptions does this require? How does this compare to the results from question one? (10 points)

To simplify notation:

* Let the point estimate of the risk difference derived via model-based standardization, $\hat{RD}$, be denoted by $\hat{\theta}$; 
* Let $n$ denote the number of bootstrapped samples indexed by $i$ (here from $i = 1$ to $i = 5000$); and
* Let each estimate of the model-standardized risk difference derived from a bootstrap sample of the original data be denoted by $\hat{\theta}_i$.

To calculate the 95% confidence interval for the model-standardized estimate of the risk difference using the Wald normal approximation

$$ \hat{\theta} \pm 1.96 \times SE_{\hat{\theta}_i}, $$

### Step One

I first calculated the mean of the differences between the original model-standardized point estimate of the risk difference $\hat{\theta} = `r round(stdized.rd, 5)`$ and the bootstrapped point estimates of the model-standardized risk difference $\hat{\theta}_i$, $\overline{\Delta_{\hat{\theta_i}}}$:

$$
\overline{\Delta_{\hat{\theta_i}}} = \frac{\sum\limits_{i = 1}^{n}(\hat{\theta}_i-\hat{\theta})}{n} = 
\frac{\sum\limits_{i = 1}^{5000}(\hat{\theta}_i-`r round(stdized.rd, 5)`)}{5000} = `r round(mean(rd.samples - stdized.rd), 3)`
$$


### Step Two

I used that mean $\overline{\Delta_{\hat{\theta_i}}}$ to calculate the sample standard deviation of the differences between the $\hat{\theta}_i$s and $\hat{\theta}$, as the best possible estimate of the standard error of that estimate, ($SE_{\hat{\theta}_i}$): 

$$
\begin{aligned}
SE_{\hat{\theta}_i} 
\approx sd(\hat{\theta}_i - \hat{\theta}) &=  
\sqrt{\frac{1}{n-1} \sum\limits_{i = 1}^{n}\left(\left(\hat{\theta}_i-\hat{\theta}\right) - \overline{\Delta_{\hat{\theta_i}}}\right)^2} \\ 
&= \sqrt{\frac{1}{5000-1} \sum\limits_{i = 1}^{5000}\left(\left(\hat{\theta}_i-`r round(stdized.rd, 5)`\right) - (`r round(mean(rd.samples - stdized.rd), 3)`)\right)^2} = 
`r round(sd.rd.boot, 3)`
\end{aligned}
$$

(Note: I did both steps one and two using the R one-liner `sd.rd.boot <- sd(rd.samples - stdized.rd)`.)

### Step Three

I calculated the Wald 95% confidence interval (CI) for the risk difference using the estimated standard error above:

$$
95\% \space CI_{\hat{\theta}} = 
\hat{\theta} \pm 1.96*SE_{\hat{\theta}_i} = 
stdized.rd  \pm 1.96 \times `r round(sd.rd.boot, 3)` = (`r round(rd.ci.norm.apx[1], 3)`, `r round(rd.ci.norm.apx[2], 3)`)
$$

### Assumptions

### Comparison to the bias-corrected and accelerated confidence interval

The 95% confidence interval for the risk difference using a normal approximation is (`r round(rd.ci.norm.apx[1], 3)`, `r round(rd.ci.norm.apx[2], 3)`), compared to the bias-corrected and accelerated confidence interval of (`r round(ci.rd.bca$bca[4], 3)`, `r round(ci.rd.bca$bca[5], 3)`).

\pagebreak

# Question Four

## Showing your work, calculate the 95% confidence interval for the risk ratio, and report your answer. (Show the formula you used, and the specific values that went into your calculation.) What assumptions does this require? How does this compare to the results from question one? (10 points)

To simplify notation:

* Let the point estimate of the risk ratio derived via model-based standardization, $\hat{RR}$, be denoted by $\hat{\theta}$; 
* Let $n$ denote the number of bootstrapped samples indexed by $i$ (here from $i = 1$ to $i = 5000$); and
* Let each estimate of the model-standardized risk ratio derived from a bootstrap sample of the original data be denoted by $\hat{\theta}_i$.

```{r results=FALSE}

log(stdized.rr)

mean(log(rr.samples) - log(stdized.rr))

```

To calculate the 95% confidence interval for the model-standardized estimate of the risk ratio using the Wald normal approximation

$$ \hat{\theta} \pm 1.96 \times SE_{\hat{\theta}_i}, $$

### Step One

I first calculated the mean of the differences between the natural logarithm of the original model-standardized point estimate of the risk ratio $\ln(\hat{\theta}) = \ln(`1.388`) = 0.328$ and the natural logarithms of the bootstrapped point estimates of the model-standardized risk ratio, $\overline{\Delta_{ln(\hat{\theta_i})}}$:

$$
\overline{\Delta_{ln(\hat{\theta_i})}} = \frac{\sum\limits_{i = 1}^{n}(\ln(\hat{\theta}_i )-\ln(\hat{\theta}))}{n} = 
\frac{\sum\limits_{i = 1}^{5000}(\ln(\hat{\theta}_i )-0.32785)}{5000} = -0.00108
$$

### Step Two

I used that mean $\overline{\Delta_{\ln(\hat{\theta_i})}}$ to calculate the sample standard deviation of the differences between the $\ln(\hat{\theta}_i)$s and $\ln(\hat{\theta})$, as the best possible estimate of the standard error of that estimate, ($SE_{\ln(\hat{\theta}_i)}$): 

$$
\begin{aligned}
SE_{\ln(\hat{\theta}_i)} 
\approx sd(\ln(\hat{\theta}_i) - \ln(\hat{\theta})) &=  
\sqrt{\frac{1}{n-1} \sum\limits_{i = 1}^{n}\left(\left(\ln(\hat{\theta}_i )-\ln(\hat{\theta})\right) - \overline{\Delta_{\ln(\hat{\theta_i})}}\right)^2} \\ 
&= \sqrt{\frac{1}{5000-1} \sum\limits_{i = 1}^{5000}\left(\left(\ln(\hat{\theta}_i)-0.32785\right) - (-0.00108)\right)^2} = 
`r round(sd.log.rr.boot, 3)`
\end{aligned}
$$

(Note: I did both steps one and two using the R one-liner `sd.log.rr.boot <- sd(log(rr.samples) - log(stdized.rr))`.)

### Step Three

I calculated the Wald 95% confidence interval (CI) for the natural logarithm of the risk ratio using the estimated standard error above:

$$
95\% \space CI_{ln(\hat{\theta})} = 
\ln(\hat{\theta}) \pm 1.96*SE_{\ln(\hat{\theta}_i)} = 
0.32785  \pm 1.96 \times 0.04159 = (`r round(log.rr.ci.norm.apx[1], 3)`, `r round(log.rr.ci.norm.apx[2], 3)`)
$$

### Step Four

I then exponentiated the confidence interval to get it on the scale of the original risk ratio:

$$
95\% \space CI_{\hat{\theta}} = e^{\ln(\hat{\theta}) \pm 1.96*SE_{\ln(\hat{\theta}_i)}} = 
(e^{`r round(log.rr.ci.norm.apx[1], 3)`}, e^{`r round(log.rr.ci.norm.apx[2], 3)`}) = 
(`r round(rr.ci.norm.apx[1], 3)`, `r round(rr.ci.norm.apx[2], 3)`)
$$

### Assumptions

For Wald confidence intervals to be valid, the following assumptions must hold:

1. The underlying population in the study must have been sampled randomly. (The bootstrapped samples from the study observations must also be drawn randomly, although this assumption is automatically pseudo-met via R's pseudo-random number generator.)  The original investigators met or didn't meet this assumption when they collected the data.

2. The underlying observations in the study population must be independent of each other. (The bootstrapped samples from the study observations must also be independent of each other, although this assumption is also pseudo-met via R's pseudo-random number generator.) The original investigators met or didn't meet this assumption when they collected the data.

3. The distribution of the natural logarithms of the risk ratios calculated from the bootstrapped samples, i.e., the sampling distribution, must be asymptotically normal, as confirmed by the plot of the distribution of the log risk ratios in step two. In particular, it must be symmetric.  (This does not necessarily mean that the distribution of the original data has to be normal, only that the distribution of the log risk ratios calculated from the bootstrapped samples has to be.)


```{r calculating cell counts, results=FALSE}

library(tidyverse)

obese_hyper_count <-
  frmgham_recoded.wide %>% 
  filter(bmi_cat == "4" & hyperten == 1) %>% 
  nrow()

obese_no_hyper_count <-
  frmgham_recoded.wide %>% 
  filter(bmi_cat == "4" & hyperten == 0) %>% 
  nrow()

ideal_hyper_count <-
  frmgham_recoded.wide %>% 
  filter(bmi_cat == "2" & hyperten == 1) %>% 
  nrow()

ideal_no_hyper_count <-
  frmgham_recoded.wide %>% 
  filter(bmi_cat == "2" & hyperten == 0) %>% 
  nrow()

obese_hyper_count
obese_no_hyper_count
ideal_hyper_count
ideal_no_hyper_count


```

4. The original dataset from which the bootstrap samples are drawn must contain sufficiently large numbers of cases and non-cases in both the exposed and unexposed categories.[^1]  Here we have 
  + `r obese_hyper_count` obese participants with hypertension (exposed cases);
  + `r obese_no_hyper_count` obese participants without hypertension (exposed non-cases);
  + `r ideal_hyper_count` "ideal"-weight participants with hypertension (unexposed cases);
  + `r ideal_no_hyper_count` "ideal"-weight participants without hypertension (unexposed cases);

so this assumption also appears met.

5. The risk ratio cannot be too close to zero, particularly in small samples, lest the CIs inaccurately include invalid negative risk ratios.[^2]

[^1]: Greenland S. Interval estimation by simulation as an alternative to and extension of confidence intervals. International Journal of Epidemiology 2004;33(6):1389–97. doi:10.1093/ije/dyh276. (Page 390.)

[^2]: Carpenter J, Bithell J. Bootstrap confidence intervals: when, which, what? A practical guide for medical statisticians. Statistics in Medicine 2000;19(9):1141–1164. doi:10.1002/(SICI)1097-0258(20000515)19:9<1141::AID-SIM479>3.0.CO;2-F. (Page 1150.)

### Comparison with bias-corrected and accelerated confidence intervals

The 95% confidence interval for the risk ratio using a normal approximation is (`r round(rr.ci.norm.apx[1], 3)`, `r round(rr.ci.norm.apx[2], 3)`), whereas
the bias-corrected and accelerated confidence interval of (`r round(ci.rr.bca$bca[4], 3)`, `r round(ci.rr.bca$bca[5], 3)`).

\pagebreak

```{r}

# My Questions

## Correct numbers?

## Is this a CID/CIR?  How long was the study period?

## More on question two?

## does prettiness of graph matter

## if we're graphing the risk ratio to show normality, why are we doing calculations on the log of it?

## assumptions for normal approximation

# Appendix: R code

```


```{r ref.label=knitr::all_labels(), echo = T, eval = F}

```

